{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Network\n",
    "## Rede neural com duas camadas ocultas para o problema de classificação de digitos utilizando o framework TensorFlow\n",
    "## A base de dados é a MNIST com 10 classes (dígitos de 0 a 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.GraphKeys.VARIABLES = tf.GraphKeys.GLOBAL_VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Definir a Arquitetura da rede:\n",
    "    - Camada de entrada = número de features = número de pixels da imagem\n",
    "      As imagens da MNIST tem 28x28 pixels, ou seja 784 features\n",
    "    - Camada de saída = número de classes = número de dígitos\n",
    "      Na MNIST temos 10 dígitos, de 0 a 9, ou seja 10 neurônios de saída\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder : alocacao de tamanho indefinido\n",
    "# variable : alocacao de tamanho pre-definido\n",
    "\n",
    "# tamanho das camadas ocultas\n",
    "L1 = 256 # camada oculta 1\n",
    "L2 = 128 # camada oculta 2\n",
    "O  = 10  # camada de saida (output)\n",
    "\n",
    "# matriz de entrada\n",
    "# placeholder do tipo float, com numero indefinido de imagens porem todas de tamanho 28x28x1\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira camada oculta (inicializacao aleatoria usando distribuicao normal)\n",
    "# matriz de pesos - 784 x L1 (784 features x L1 neuronios da camada oculta 1)\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L1], stddev=0.1))\n",
    "# termos bias - L1, um para cada neuronio\n",
    "b1 = tf.Variable(tf.truncated_normal([L1], stddev=0.1))\n",
    "\n",
    "# Segunda camada oculta\n",
    "# matriz de pesos - L1 x L2 (256 x 128 neuronios)\n",
    "W2 = tf.Variable(tf.truncated_normal([L1, L2], stddev=0.1))\n",
    "# termos bias - L2, um para cada neuronio\n",
    "b2 = tf.Variable(tf.truncated_normal([L2], stddev=0.1))\n",
    "\n",
    "# Camada de saida (idem, agora transformando para as 10 classes finais)\n",
    "W3 = tf.Variable(tf.truncated_normal([L2, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.truncated_normal([10], stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camada de saida (rotulos reais)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Definir como serão feitos os cálculos;\n",
    "uso de multiplicação matricial! \n",
    "\n",
    "$$f_1(\\mathbf{x}_1) = \\operatorname{relu}(W_1\\mathbf{x}_1 + \\mathbf{b}_1) = \\mathbf{x}_2$$\n",
    "$$f_2(\\mathbf{x}_2) =  \\operatorname{relu}(W_2\\mathbf{x}_2 + \\mathbf{b}_2) = \\mathbf{x}_3$$\n",
    "$$f_3(\\mathbf{x}_3) = \\operatorname{softmax}(W_3\\mathbf{x}_3 + \\mathbf{b}_3) = \\hat{\\mathbf{y}}$$\n",
    "\n",
    "inicializar os pesos e outras variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # instancia inicializacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As predicoes sao dadas pela formula anterior\n",
    "X1 = tf.reshape(X, [-1, 784])  # vetoriza as imagens\n",
    "\n",
    "X2 = tf.nn.relu(tf.matmul(X1,W1) + b1)\n",
    "X3 = tf.nn.relu(tf.matmul(X2,W2) + b2)\n",
    "\n",
    "# formula para as probabilidades de saida\n",
    "X4 = tf.matmul(X3,W3) + b3\n",
    "Y_ = tf.nn.softmax( X4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Funcao de custo: informa quão longe estamos da solução ideal\n",
    "    Entropia cruzada\n",
    "    $$\\sum_{i=0}^{N} -(Y \\cdot \\log(\\hat Y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossEnt = tf.nn.softmax_cross_entropy_with_logits(logits=X4, labels=Y)\n",
    "crossEnt = tf.reduce_mean(crossEnt)*batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alem da funcao de custo vamos calcular tambem a acuracia\n",
    "# Y[i]  = [0   , 0  , 0  , 1  ,  0  , 0  , 0  , 0  , 0  , 0  ] -> vetor rotulo real\n",
    "# X4[i] = [0.1 , 0  , 0.2, 0.7,  0  , 0  , 0  , 0  , 0  , 0  ] -> probabilidades preditas\n",
    "# Y_[i] = [0   , 0  , 0 ,  1  ,  0  , 0  , 0  , 0  , 0  , 0  ] -> rotulo predito pela rede\n",
    "correctPred = tf.equal( tf.argmax(Y_,1), tf.argmax(Y,1) )\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Metodo de otimizacao e suas variaveis\n",
    "\n",
    "    *Gradiente Descendente* ou versões: RMSProp, Adam, etc.\n",
    "    *Taxa de Aprendizado* = 0.003\n",
    "    *Batch size* = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 0.003\n",
    "batchSize = 64\n",
    "iterations = 5\n",
    "\n",
    "optMethod = tf.train.AdamOptimizer(lrate) # metodo alternativo de otimizacao\n",
    "trainProcess = optMethod.minimize(crossEnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Rodar um experimento com a MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = mnist_data.read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessao TensorFlow\n",
    "sess = tf.Session() # instancia a sessao\n",
    "sess.run(init) # inicializa variaveis com o objeto que criamos anteriormente (init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss: 33.9248 Accuracy: 89.0625%\n",
      "1 Loss: 18.2534 Accuracy: 89.0625%\n",
      "2 Loss: 19.3333 Accuracy: 90.625%\n",
      "3 Loss: 21.0635 Accuracy: 90.625%\n",
      "4 Loss: 24.354 Accuracy: 95.3125%\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    # carrega batch um par Imagem, Rotulo\n",
    "    batX, batY = mnist.train.next_batch(batchSize)\n",
    "    # passar para o tensorflow, preciso definir um dicionario\n",
    "    # o dicionario contem o batch no formato Chave, Valor: Imagens, Rotulos\n",
    "    # a 'chave' deve ser a mesma que definimos como placeholders para a arquitetura\n",
    "    # nesse caso X e Y\n",
    "    trainData = {X: batX, Y: batY}\n",
    "    # executa uma iteracao (feed-forward e backpropagation)\n",
    "    sess.run(trainProcess, feed_dict=trainData)\n",
    "    \n",
    "    loss = sess.run(crossEnt, feed_dict=trainData)\n",
    "    acc  = sess.run(accuracy, feed_dict=trainData)\n",
    "    print(str(i) + \" Loss: \" + str(loss) + \" Accuracy: \"+str(acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Avaliar o modelo em dados nao vistos no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 91.1099970341%\n"
     ]
    }
   ],
   "source": [
    "testData = {X: mnist.test.images, Y: mnist.test.labels}\n",
    "accTest  = sess.run(accuracy, feed_dict=testData)\n",
    "print(\"Accuracy on test data: \" + str(accTest*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
